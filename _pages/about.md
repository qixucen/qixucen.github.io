---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
HelloğŸ‘‹, here is a person who stumbled into the field of AI by accident and still hasn't left. He graduated from the Gaoling School of Artificial Intelligence at Renmin University of China with a bachelor's degree.

He is passionate about hackathons and has secured significant prizes in various competitions organized by prominent Chinese internet companies. His motto is to venture forth like bounty hunters!

His research interests primarily focus on Natural Language Processing (NLP), particularly Large Language Model (LLM)-based Agents and LLM Reasoning. Recently, his work has centered on agentic workflow optimization and the development of reasoning frameworks leveraging inference-time scaling techniques. His research in this area began during his internship at [Kwai](https://www.kuaishou.com/), where he gained hands-on experience in exploring and advancing these technologies.

# ğŸ”¥ News
- *2024.02.11*: &nbsp;ğŸ¥³ğŸ¥³ [AFlow](https://arxiv.org/abs/2410.10762) is accepted by ICLR 2025 as an <span style="color: red;">Oral</span>!
- *2024.10.15*: &nbsp;ğŸ“‘ğŸ“‘ Life's first paper! Please explore our innovative work on the Automated Agentic Workflow.
- *2024.06.13*: &nbsp;ğŸ‰ğŸ‰ My team got the third place in the Alibaba 2024 Global Mathematics Competition AI Challenge! ğŸ¥‰ ($2000 bonus)

# ğŸ“ Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2025 <span style="color: red;">Oral</span></div><img src='images/aflow.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[ICLR 2025 Oral (1.8%)]** AFlow: Automating Agentic Workflow Generation \[[paper](https://arxiv.org/abs/2410.10762)\]\[[code](https://github.com/didiforgithub/MetaGPT-MathAI/tree/main/examples/ags)\]\[[report](https://mp.weixin.qq.com/s/5YpPFYIpuCkSf0sJp0_RnQ)\]

Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, **Fengwei Teng**, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu

We introduces AFlow, an automated framework that reformulates workflow optimization as a search problem over code-represented workflows, using Monte Carlo Tree Search to efficiently explore and refine workflows through code modification and execution feedback. By leveraging this approach, AFlow achieves superior performance compared to state-of-the-art baselines across multiple benchmarks, while also enabling smaller models to outperform larger ones at a fraction of the cost.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ARXIV</div><img src='images/aot.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**[ARXIV]** Atom of Thoughts for Markov LLM Test-Time Scaling \[[paper](https://arxiv.org/abs/2502.12018)\]\[[code](https://github.com/qixucen/atom)\]\[[huggingface daily](https://huggingface.co/papers/2502.12018)\]

**Fengwei Teng**, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo

We introduce Atom of Thoughts (AoT), a novel reasoning framework that transforms complex reasoning processes into a Markov-style sequence of atomic questions. By implementing a two-phase transition mechanism of decomposition and contraction, AoT eliminates the need to maintain historical dependencies during reasoning, allowing models to focus computational resources on the current question state. Experiments across multiple benchmarks demonstrate AoT's effectiveness both as a standalone framework and as a plug-in enhancement for existing test-time scaling methods.

</div>
</div>

# ğŸ– Honors and Awards
- *2024.06* Alibaba Global Mathematics Competition AI Challenge - Third Place AwardğŸ¥‰ (3rd out of 563 teams) ($2000)
\[[code](https://github.com/didiforgithub/MetaGPT-MathAI)\]
- *2023.12* Baidu & FounderPark AGI Hackathon - Second Place AwardğŸ¥ˆ (Â¥10000)
\[[code](https://github.com/didiforgithub/Prompt-Navigator)\]
- *2023.05* The International Mathematical Contest in Modeling (MCM) - Meritorious Award
\[[pdf](https://www.overleaf.com/read/vpvcsksqyrfz#5df8c5)\]
- *2022.12* The Chinese Mathematics Competitions - Second Prize Award

# ğŸ“– Educations
- *2020.09 - 2024.06* B. Eng in Artificial, Renmin University of China, Gaoling School of Artificial Intelligence <span style="float: right;">Beijing, China</span>
  - Graduation thesis recommendation


# ğŸ’¬ Invited Talks
I have given two speeches in Chinese about the Alibaba Global Mathematics Competition AI Challenge. Once there is a replay video link, I will update it in a timely manner.

# ğŸ’» Internships
- *2023.09 - 2024.01* <img src="images/kuaishou.png" alt="" style="width: auto; height: 1em; vertical-align: middle;">Kwai Technology
  - Research Focus: LLM-based Agents; Advanced Data Analysis
  - Main Contributions:
    - Define the code for data analysis and visualization as a finite automaton process, by learning transfer equations as tools from successful trajectories, defining a correct trajectory through a finite number of ordered calls to functions in the transfer equation library.
    - To address the challenge of white boxing, use retrieval-augmentation methods to provide a visual explanation process for each tool calling, enhancing users' confidence in the results provided by the AI copilot.
- *2023.05 - 2023.07* <img src="https://img.36krcdn.com/hsossms/20230424/v2_06078b14341f4486835b4b05ec8d8fb4@000000_oswg7548oswg132oswg132_img_000" style="width: auto; height: 1em; vertical-align: middle;">Deep Space Symphony
  - Research Focus: Music-Driven Motion Diffusion; Controllable Generation
  - Main Contributions:
    - Combine VQVAE and Diffusion: independently train VQVAE on motion sequences to obtain discrete code book of keyframe, add music features in the attention during the diffusion phase, then obtain the prior of VQVAE in the encoder stage, and restore it to a music-driven motion sequence in the decoder stage.
    - Utilize choreography knowledge for fine-grained generation: edit discrete codes on time series and constrain discrete codes according to beats; perform lyrics-music separation for music with lyrics and repeat actions according to the lyrics.

# æš—è‰²æ¨¡å¼å’Œäº’åŠ¨æ€§ä¼˜åŒ–æ–¹æ¡ˆ

åœ¨ç½‘é¡µå¼€å‘ä¸­ï¼Œæä¾›æš—è‰²æ¨¡å¼å·²ç»æˆä¸ºç°ä»£ç½‘ç«™çš„æ ‡å‡†åŠŸèƒ½ä¹‹ä¸€ã€‚æˆ‘æ³¨æ„åˆ°æ‚¨çš„å­¦æœ¯ä¸»é¡µå·²ç»æœ‰äº†æš—è‰²æ¨¡å¼åˆ‡æ¢æŒ‰é’®ï¼Œä½†ç‚¹å‡»æ—¶æ²¡æœ‰æ•ˆæœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥å¢å¼ºç½‘ç«™çš„äº’åŠ¨æ€§ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚

ä¸»è¦é—®é¢˜æ˜¯æš—è‰²æ¨¡å¼åˆ‡æ¢åŠŸèƒ½æ²¡æœ‰å®é™…å®ç°ï¼ŒæŒ‰é’®å­˜åœ¨ä½†æ²¡æœ‰å¯¹åº”çš„JavaScriptä»£ç æ¥å¤„ç†ç‚¹å‡»äº‹ä»¶ã€‚æˆ‘å°†æä¾›ä¿®å¤æ–¹æ¡ˆåŠå…¶ä»–äº¤äº’æ”¹è¿›ã€‚

## ä¿®æ”¹æ–¹æ¡ˆ

### 1. æ·»åŠ æš—è‰²æ¨¡å¼CSSæ ·å¼å’ŒJavaScriptåŠŸèƒ½

```css:assets/css/main.scss
/* Dark Theme Styles */
:root {
  --bg-color: #ffffff;
  --text-color: #333333;
  --link-color: #4B6CB7;
  --header-bg: #ffffff;
  --border-color: #ddd;
  --code-bg-color: #f5f5f5;
  --box-shadow: 0 1px 1px rgba(0, 0, 0, 0.125);
}

.dark-theme {
  --bg-color: #1a1a1a;
  --text-color: #f0f0f0;
  --link-color: #8cb4ff;
  --header-bg: #222222;
  --border-color: #444;
  --code-bg-color: #2d2d2d;
  --box-shadow: 0 1px 1px rgba(255, 255, 255, 0.05);
  
  background-color: var(--bg-color);
  color: var(--text-color);
  
  a:not(.btn) {
    color: var(--link-color);
  }
  
  .masthead {
    background-color: var(--header-bg);
    border-bottom: 1px solid var(--border-color);
  }
  
  .author__urls-wrapper {
    background-color: var(--bg-color);
  }
  
  .author__urls {
    background-color: var(--bg-color);
    color: var(--text-color);
  }
  
  code {
    background-color: var(--code-bg-color);
  }
  
  pre {
    background-color: var(--code-bg-color);
  }
  
  th, td {
    border-bottom: 1px solid var(--border-color);
  }
  
  .profile_box {
    background-color: var(--bg-color);
    box-shadow: var(--box-shadow);
  }
}

/* Apply default theme variables to non-dark-theme elements */
body {
  background-color: var(--bg-color);
  color: var(--text-color);
}

.masthead {
  background-color: var(--header-bg);
}

a:not(.btn) {
  color: var(--link-color);
}
```

### 2. æ›´æ–°JavaScriptå®ç°æš—è‰²æ¨¡å¼åˆ‡æ¢åŠŸèƒ½

```javascript:assets/js/custom.js
// æ·»åŠ å¹³æ»‘æ»šåŠ¨æ•ˆæœ
document.addEventListener('DOMContentLoaded', function() {
  // è·å–æ‰€æœ‰å¯¼èˆªé“¾æ¥
  const navLinks = document.querySelectorAll('.masthead__menu-item a');
  
  // æ·»åŠ ç‚¹å‡»äº‹ä»¶ç›‘å¬å™¨
  navLinks.forEach(link => {
    link.addEventListener('click', function(e) {
      // åªå¯¹é”šç‚¹é“¾æ¥è¿›è¡Œå¤„ç†
      if (this.getAttribute('href').startsWith('#')) {
        e.preventDefault();
        
        const targetId = this.getAttribute('href');
        const targetElement = document.querySelector(targetId);
        
        if (targetElement) {
          // ... existing code ...
        }
      }
    });
  });
  
  // ... existing code ...
  
  // ä¸»é¢˜åˆ‡æ¢åŠŸèƒ½
  const themeToggle = document.getElementById('theme-toggle');
  const themeIcon = themeToggle.querySelector('i');
  
  // æ£€æŸ¥ç”¨æˆ·ä¹‹å‰æ˜¯å¦è®¾ç½®äº†ä¸»é¢˜åå¥½
  const currentTheme = localStorage.getItem('theme');
  if (currentTheme === 'dark') {
    document.body.classList.add('dark-theme');
    themeIcon.classList.remove('fa-moon');
    themeIcon.classList.add('fa-sun');
  }
  
  // ç‚¹å‡»æŒ‰é’®åˆ‡æ¢ä¸»é¢˜
  themeToggle.addEventListener('click', function(e) {
    e.preventDefault();
    
    // åœ¨bodyä¸Šåˆ‡æ¢æš—è‰²ä¸»é¢˜ç±»
    document.body.classList.toggle('dark-theme');
    
    // æ›´æ–°å›¾æ ‡
    if (document.body.classList.contains('dark-theme')) {
      themeIcon.classList.remove('fa-moon');
      themeIcon.classList.add('fa-sun');
      localStorage.setItem('theme', 'dark');
    } else {
      themeIcon.classList.remove('fa-sun');
      themeIcon.classList.add('fa-moon');
      localStorage.setItem('theme', 'light');
    }
  });
  
  // æ·»åŠ æ»šåŠ¨åŠ¨ç”»
  const animateElements = document.querySelectorAll('h1, h2, h3, p, ul, .profile_box');
  
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        entry.target.classList.add('animate-on-scroll');
        observer.unobserve(entry.target);
      }
    });
  }, {
    threshold: 0.1
  });
  
  // è§‚å¯Ÿæ‰€æœ‰éœ€è¦åŠ¨ç”»çš„å…ƒç´ 
  animateElements.forEach(el => {
    observer.observe(el);
  });
});
```

## åŠŸèƒ½è¯´æ˜

1. **æš—è‰²æ¨¡å¼åˆ‡æ¢**ï¼š
   - ä¿®å¤äº†æš—è‰²æ¨¡å¼åˆ‡æ¢æŒ‰é’®çš„åŠŸèƒ½
   - åœ¨æš—è‰²å’Œäº®è‰²æ¨¡å¼ä¹‹é—´åˆ‡æ¢æ—¶è‡ªåŠ¨å˜æ›´å›¾æ ‡ï¼ˆæœˆäº®/å¤ªé˜³ï¼‰
   - ä½¿ç”¨localStorageä¿å­˜ç”¨æˆ·åå¥½ï¼Œåœ¨ç”¨æˆ·ä¸‹æ¬¡è®¿é—®æ—¶è‡ªåŠ¨åº”ç”¨

2. **å“åº”å¼è®¾è®¡å¢å¼º**ï¼š
   - æ·»åŠ äº†CSSå˜é‡æ¥æ§åˆ¶é¢œè‰²ä¸»é¢˜
   - ç¡®ä¿åœ¨æš—è‰²æ¨¡å¼ä¸‹æ‰€æœ‰å…ƒç´ éƒ½æœ‰åˆé€‚çš„å¯¹æ¯”åº¦

3. **äº¤äº’æ€§æ”¹è¿›**ï¼š
   - ä¿ç•™äº†ç°æœ‰çš„å¹³æ»‘æ»šåŠ¨åŠŸèƒ½
   - ä¿ç•™äº†ç°æœ‰çš„æ»šåŠ¨åŠ¨ç”»æ•ˆæœ

è¿™äº›æ›´æ”¹å°†ä½¿æ‚¨çš„å­¦æœ¯ä¸»é¡µæ›´åŠ ç°ä»£åŒ–ã€ç”¨æˆ·å‹å¥½ï¼ŒåŒæ—¶ä¹Ÿå¢å¼ºäº†ç½‘ç«™çš„å¯è®¿é—®æ€§ã€‚